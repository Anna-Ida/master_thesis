{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f5d929",
   "metadata": {},
   "source": [
    "# EOF analysis and PC regression\n",
    "Notebook to do the complete analysis of:\n",
    "* selecting a subset of data (e.g. winter months)\n",
    "* EOF analysis\n",
    "* PC regression\n",
    "\n",
    "for a number of different model data, as well as \n",
    "* comparing the analysis results of the different models visually and statistically with Taylor diagrams\n",
    "\n",
    "Required input: pre-processed data (e.g. with CDO):\n",
    "* required years\n",
    "* required geographical domain\n",
    "* de-trended\n",
    "* converted to one grid\n",
    "\n",
    "REQUIRED FILE STRUCTURE:\n",
    "* Folder 'Functions' with external functions\n",
    "* Folder 'data' with subfolders for each model containing files for geopotential height, temperature and precipitation\n",
    "    * named 'region_variable_tempresolution_model_scenario_variant_grid_timeframe_detrended_grid.nc'\n",
    "    * e.g. 'NA_zg_Amon_CESM2_historical_r1i1p1f1_gn_185001-201412_detrended_regriddedtoIPSL.nc' \n",
    "* Folder 'output' with subfolders for each model, as well as subfolders 'plots', 'taylordiagrams', 'mean_diff', 'PCRplots' for model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ff6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ff837",
   "metadata": {},
   "source": [
    "### Import required packages and external functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8790a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d0386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset, num2date\n",
    "import matplotlib as mpl\n",
    "from matplotlib import gridspec,cm, rcParams, pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from eofs.standard import Eof\n",
    "from eofs.tools.standard import correlation_map, covariance_map\n",
    "from os.path import exists\n",
    "import sys  \n",
    "from uncertainties import ufloat, unumpy\n",
    "# mapping:\n",
    "from cartopy import config, crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import skill_metrics as sm\n",
    "\n",
    "\n",
    "# import my own functions:\n",
    "# (stored in the same location as this Notebook in a folder \"Functions\")\n",
    "sys.path.append('Functions')\n",
    "from data_selection import subset_data, select_extreme_quartiles, find_month_from_index, select_extreme_months\n",
    "from EOF_analysis import EOF_analysis, plot_mean_field_func, plot_EOFs, plot_PCs\n",
    "from PC_regression import PC_regression, plot_PCR, plot_mean_field\n",
    "from naming_functions import name_files, plot_titles\n",
    "from detrending import detrend_files\n",
    "from plot_extremes import select_extremes, plot_extremes_in_PCs, plot_mean_fields_of_extr_months\n",
    "from plotting_functions import plot_map, plot_PCR1, plot_meandiffs, plot_eigenvalues, plot_1_PCR1\n",
    "from model_comparison import plot_mean_plus_diff, plot_diff_map, plot_diff_p_map, plot_4_diff_map, plot_EOFs_plus_gradlocs, plot_EOF1_plus_gradlocs  \n",
    "from model_comparison import calc_gradients, test_gradient_overlap, z_test_two_means, plot_mean_diff_ranking, plot_gradient_ranking\n",
    "from model_comparison2 import taylor_metrics, GL_taylor_metrics, skill_score, plot_taylor_diagrams, plot_1_taylor_diagram, weighted_skillscore\n",
    "\n",
    "\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b851ba",
   "metadata": {},
   "source": [
    "### Define variables for the used data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = ['ERA5', 'CESM2', 'CNRM-ESM2-1', 'EC-Earth3 r1', 'EC-Earth3 r10', 'IPSL-CM6A-LR', 'MIROC6', 'MPI-ESM1-2-HR', 'UKESM1-0-LL']#, 'EC-Earth3', 'EC-Earth3']\n",
    "variants = ['','r1i1p1f1', 'r1i1p1f2',   'r1i1p1f1',     'r10i1p1f1',   'r1i1p1f1',   'r1i1p1f1',  'r1i1p1f1',     'r1i1p1f2']   \n",
    "\n",
    "\n",
    "types = {1:'allmonths',2:'monthly',3:'seasonal'}\n",
    "seasons = {'winter':'DJF', 'spring':'MAM', 'summer':'JJA', 'fall':'SON','extended cold':'NDJFM'}\n",
    "months = {1:'January',2:'February',3:'March',4:'April',5:'May',6:'June',7:'July',8:'August',9:'September',10:'October',11:'November',12:'December'}\n",
    "regtypes = ['regression','correlation', 'covariance']\n",
    "regdatatypes = ['Geopotential height','Precipitation', 'Temperature']\n",
    "regdatatypes_short = {'Geopotential height':'zgs','Precipitation':'pr', 'Temperature':'tas'}\n",
    "regdatatypes_units = {'Geopotential height':'[m]','Precipitation':'[mm/day]', 'Temperature':'[°C]'}\n",
    "\n",
    "\n",
    "# swap EOFs if necessary to compare same patterns (e.g. EA with EA):\n",
    "orders = np.array([[0,1,2,3], # ERA5\n",
    "                  [0,1,3,2], # CESM2\n",
    "                  [0,1,3,2], # CNRM\n",
    "                  [0,2,1,3], # EC-Earth r1\n",
    "                  [0,1,2,3], # EC-Earth r10\n",
    "                  [0,1,2,3], # IPSL\n",
    "                  [0,1,3,2], # MIROC6 \n",
    "                  [0,1,2,3], # MPI\n",
    "                  [0,2,3,1]  # UKESM\n",
    "                  #[0,2,1,3]  # EC-Earth r101 \n",
    "                  ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510728d",
   "metadata": {},
   "source": [
    "### Define analysis settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af7011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "height_level = 5                         # 5 = geopotential height at 500 hPa\n",
    "analysis_type = types[3]                 # 3 = seasonal\n",
    "season = seasons['extended cold']\n",
    "season_mean = True\n",
    "running_mean = 1                         # if 1, no running mean, just seasonal mean is used\n",
    "month = months[1]                        # only relevant if analysis_type = monthly\n",
    "reg_type = regtypes[0]                   # 0 = regression\n",
    "regdata_type = regdatatypes[2]\n",
    "regridded_text='_regriddedtoIPSL'\n",
    "\n",
    "# optional: look at extremes in sub-region (Greenland):\n",
    "extremes=False\n",
    "extr_type = 'invalid'\n",
    "extreme_region = 'Gl_masked'#'NE' \n",
    "extreme_region_name = 'Greenland' #if (extreme_region=='Gl')\n",
    "nmonths = 5 # how many extreme months to look at (at least 5)\n",
    "\n",
    "startyear, endyear = 1959, 2014\n",
    "timeframe_long, timeframe = f'{startyear}01-{endyear}12', f'{startyear}-{endyear}' \n",
    "\n",
    "n_eofs = 4\n",
    "norm_PC = False                  # normalize PCs by their sum per month, to show relative importance of the leading 4?\n",
    "\n",
    "# plotting:\n",
    "n_colorlevels = 11               # colorlevels for plotting\n",
    "plot_mean_field = True\n",
    "add_eof_pattern = True\n",
    "mark_high_corr=False\n",
    "mask_low_corr=False #True\n",
    "corr_threshold=0.3               # threshold to consider correlation coefficient 'high' or robust\n",
    "fixed_bounds= True #False        # use prescribed limits to standardize colorscale for all regression plots (see Functions>PC_regression.py)\n",
    "\n",
    "savemean = True\n",
    "saveEOF = True \n",
    "savePC = True \n",
    "savePCreg = True\n",
    "savemetrics = True\n",
    "Greenland_analysis=False\n",
    "\n",
    "regression_loop = [0,1,2]        # Do geopotential height, temperature and precipitation regression \n",
    "# (numbers refer to 'regdatatypes' above)\n",
    "\n",
    "\n",
    "comp_dims = 21 \n",
    "# size of the arrays containing the comparison results\n",
    "# 0 = mean zg field, 1 - 5 = eofs 1 - 4, 6 - 9 = PCR 1 -4, 10 - 13 = high corr PCR 1-4, 14-21 GL PCR\n",
    "ccoef = np.zeros((comp_dims,len(models)))\n",
    "sdev = np.zeros((comp_dims,len(models)))\n",
    "mse = np.zeros((comp_dims,len(models)))\n",
    "rmse = np.zeros((comp_dims,len(models)))\n",
    "\n",
    "mean_diff_arr = np.zeros((2,len(models)))   # normal and significant differences\n",
    "NAO_grad = np.zeros((2,len(models)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c790f54a",
   "metadata": {},
   "source": [
    "## EOF & PCR execution:\n",
    "DO EOF analysis and PC regression for each model and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bafde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "savedata = True\n",
    "loaddata = False #True #False    # if True loads EOFs/PCs and regression coefficients that have been calculated and saved in previous runs to save computation time\n",
    "\n",
    "\n",
    "regression_loop = [0,1,2]        # Do geopotential height, temperature and precipitation regression \n",
    "# (numbers refer to 'regdatatypes' above)\n",
    "\n",
    "for regressiontype in regression_loop:    \n",
    "    regdata_type = regdatatypes[regressiontype] \n",
    "    print(f'--- {regdata_type} Regression ---')\n",
    "\n",
    "    for modeli in range(len(models)):\n",
    "        model = models[modeli]\n",
    "        print(model)\n",
    "        variant = variants[modeli]\n",
    "        order = orders[modeli]\n",
    "        #grid = 'gr' if (modeli in [0,1,2,3,8,9]) else 'gn'\n",
    "        grid = 'gr' if (modeli in [0,2,3,4,5]) else 'gn'               # check that this is consistent with the naming in the used model data\n",
    "        timeframe = f'{startyear}-{endyear}'    \n",
    "        if (model=='ERA5'):\n",
    "            eofvar = 'z' \n",
    "            regvar = 'tp' if (regdata_type=='Precipitation') else 't2m'\n",
    "        else:\n",
    "            eofvar = 'zg'\n",
    "            regvar = 'pr' if (regdata_type=='Precipitation') else 'tas'\n",
    "        if (regdata_type=='Geopotential height'):\n",
    "            regvar = eofvar \n",
    "\n",
    "\n",
    "\n",
    "        if (model=='ERA5'):\n",
    "            startyear, endyear = 1959, 2020\n",
    "        else:\n",
    "            startyear, endyear = 1850, 2014  \n",
    "        timeframe, timeframe_long = f'{startyear}-{endyear}' ,  f'{startyear}01-{endyear}12'\n",
    "        # input files:\n",
    "        base_filename = f'Amon_{model}_historical_{variant}_{grid}_{timeframe_long}'\n",
    "        eof_infile_detrended_nc = f'data/{model}/NA_{eofvar}_{base_filename}_detrended{regridded_text}.nc'\n",
    "        regression_infile = f'data/{model}/NA_{regvar}_{base_filename}_detrended{regridded_text}.nc' \n",
    "\n",
    "        dataset = Dataset(eof_infile_detrended_nc)\n",
    "        lats, lons = dataset.variables['lat'][:] , dataset.variables['lon'][:] \n",
    "        zgs_detrended = dataset.variables[eofvar] \n",
    "        if (model=='ERA5'):\n",
    "            zgs = zgs_detrended[:] / 9.80665             # to turn geopotential into geopotential height\n",
    "        elif (len(np.shape(zgs_detrended))>3):             # if variable has several height levels\n",
    "            print(f' Shape original data: {np.shape(zgs_detrended)}')\n",
    "            zgs = zgs_detrended[:,height_level, :, :]    # select geopotential height at 500 hPa (= 5000 Pa)\n",
    "        else:\n",
    "            zgs = zgs_detrended \n",
    "        model_zg_data = subset_data(zgs, analysis_type, season, season_mean, month, running_mean)\n",
    "        #model_zg_mean = np.mean(model_zg_data, axis=0)\n",
    "\n",
    "        # load regression data:\n",
    "        if (regdata_type=='Geopotential height'):\n",
    "            model_reg_data = model_zg_data\n",
    "        else:\n",
    "            reg_dataset = Dataset(regression_infile)\n",
    "            reg_data_raw = reg_dataset.variables[regvar] \n",
    "            model_reg_data = subset_data(reg_data_raw, analysis_type, season, season_mean, month, running_mean)\n",
    "            if (regdata_type=='Temperature'):  # transform from K to °C\n",
    "                model_reg_data -= 273.15\n",
    "            if (regdata_type=='Precipitation'):  # transform to mm/day\n",
    "                if (model=='ERA5'):              # from m/day \n",
    "                    model_reg_data *= 1000\n",
    "                else:                            # from kg/m2/s\n",
    "                    model_reg_data *= 86400\n",
    "\n",
    "        model_regdata_mean = np.mean(model_reg_data, axis=0)\n",
    "\n",
    "        if (len(model_reg_data)==55):\n",
    "            startyear, endyear = 1959, 2014\n",
    "            timeframe_long = f'{startyear}01-{endyear}12'\n",
    "            timeframe = f'{startyear}-{endyear}' \n",
    "\n",
    "\n",
    "        # EOF & PCR: ------------------------\n",
    "        ID, savemeanas, saveEOFas, savePCas, savePCregas, saveregmeanas, saveEOFdataas, savePCRdataas, saveextremesplotas, saveextremesmapas = name_files(analysis_type,month,season,season_mean,running_mean,extremes,extr_type,extreme_region,nmonths,timeframe,model,variant,n_eofs,regdatatypes_short,regdata_type,reg_type,mask_low_corr,regridded_text)\n",
    "        standard_title, base_title = plot_titles(season_mean,running_mean,extremes,extr_type,extreme_region_name,model,variant,season,timeframe)\n",
    "\n",
    "        model_eofs, model_pcs, model_varfrac = EOF_analysis(model_zg_data, lats, lons, n_eofs, analysis_type, season, season_mean, \n",
    "                                                            timeframe, model, variant, ID, running_mean, extremes, startyear, endyear, standard_title,\n",
    "                                                            savedata, saveEOFdataas, loaddata, savemean, savemeanas, saveEOF, saveEOFas, norm_PC, savePC, savePCas, n_colorlevels, plot_mean_field=True,order=order)\n",
    "\n",
    "        model_coefficients, model_corrcoeffs = PC_regression(model_reg_data, reg_type, regdata_type, regdatatypes_units, lats, lons, model_pcs, n_colorlevels, model_eofs, model_varfrac,\n",
    "                                                             loaddata, savedata, savePCRdataas, model, saveregmeanas,\n",
    "                                                             add_eof_pattern, mark_high_corr, mask_low_corr, corr_threshold, standard_title, savePCreg, savePCregas, fixed_bounds, order)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a717a4bd",
   "metadata": {},
   "source": [
    "## Model comparison\n",
    "- Calculate the metrics to copmare the results from each model against each other\n",
    "- Plot difference plots and Taylor diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4dd1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "\n",
    "loaddata = False     # if True loads coefficients that have been calculated and saved in previous runs to save computation time\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "regression_loop = [0,1,2]\n",
    "\n",
    "for regressiontype in regression_loop:   \n",
    "    regdata_type = regdatatypes[regressiontype] \n",
    "    print(f'--- {regdata_type} Regression ---')\n",
    "\n",
    "    # load ERA5 data as base for comparison:\n",
    "    # --------------------------------------------------\n",
    "    model = models[0]\n",
    "    variant = variants[0]\n",
    "    order = orders[0]  \n",
    "    eofvar = 'z' \n",
    "    regvar = 'tp' if (regdata_type=='Precipitation') else 't2m'\n",
    "    if (regdata_type=='Geopotential height'):\n",
    "        regvar = eofvar \n",
    "    season = 'NDJFM'\n",
    "    meantext = 'mean1'\n",
    "    extr_text = ''\n",
    "\n",
    "    obs_zg_mean = np.load(f'data/{model}/meanzg_4EOFs_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "    obs_reg_data = np.load(f'data/{model}/reg_data_PC_{regdatatypes_short[regdata_type]}_regression_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "    obs_regdata_mean = np.load(f'data/{model}/meanfield_PC_{regdatatypes_short[regdata_type]}_regression_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "    obs_eofs = np.load(f'data/{model}/eofs_4EOFs_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "    obs_pcs = np.load(f'data/{model}/pcs_4EOFs_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "    obs_varfrac = np.load(f'data/{model}/varfrac_4EOFs_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "    obs_coefficients = np.load(f'data/{model}/coeffs_PC_{regdatatypes_short[regdata_type]}_regression_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "    obs_corrcoeffs = np.load(f'data/{model}/corrcoeffs_PC_{regdatatypes_short[regdata_type]}_regression_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "\n",
    "\n",
    "    obs_file = f'data/ERA5/NA_z_Amon_ERA5_historical_1_gr_195901-202012_detrended{regridded_text}.nc'\n",
    "    dataset = Dataset(obs_file)\n",
    "    lats, lons = dataset.variables['lat'][:] , dataset.variables['lon'][:] \n",
    "  \n",
    "\n",
    "    \n",
    "\n",
    "##### load model data to compare with ERA5:\n",
    "    # ----------------------------------------------------\n",
    "    for modeli in range(len(models)):\n",
    "        model = models[modeli]\n",
    "        print(model)\n",
    "        variant = variants[modeli]\n",
    "        order = orders[modeli]\n",
    "        grid = 'gr' if (modeli in [0,2,3,4,5]) else 'gn'  \n",
    "        if (model=='ERA5'):\n",
    "            eofvar = 'z' \n",
    "            regvar = 'tp' if (regdata_type=='Precipitation') else 't2m'\n",
    "        else:\n",
    "            eofvar = 'zg'\n",
    "            regvar = 'pr' if (regdata_type=='Precipitation') else 'tas'\n",
    "        if (regdata_type=='Geopotential height'):\n",
    "            regvar = eofvar \n",
    "         \n",
    "        \n",
    "        model_zg_mean = np.load(f'data/{model}/meanzg_4EOFs_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "        model_eofs = np.load(f'data/{model}/eofs_4EOFs_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "        model_pcs = np.load(f'data/{model}/pcs_4EOFs_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "        model_varfrac = np.load(f'data/{model}/varfrac_4EOFs_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "        model_reg_data = np.load(f'data/{model}/reg_data_PC_{regdatatypes_short[regdata_type]}_regression_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "        model_regdata_mean = np.load(f'data/{model}/meanfield_PC_{regdatatypes_short[regdata_type]}_regression_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "        model_coefficients = np.load(f'data/{model}/coeffs_PC_{regdatatypes_short[regdata_type]}_regression_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "        model_corrcoeffs = np.load(f'data/{model}/corrcoeffs_PC_{regdatatypes_short[regdata_type]}_regression_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# COMPARISON ANALYSIS:\n",
    "# ---------------------------------------------------  \n",
    "        standard_title, base_title = plot_titles(season_mean,running_mean,extremes,extr_type,extreme_region_name,model,variant,season,timeframe)\n",
    "        \n",
    "        latweights = np.array(np.cos(np.deg2rad(lats)))  \n",
    "        area_weights = np.tile(latweights, (len(lons), 1)).T\n",
    "\n",
    "\n",
    "        PCR1fig = plot_1_PCR1(regdata_type, model_eofs, model_varfrac, model_coefficients, model_corrcoeffs, n_colorlevels, lons, lats, regdatatypes_units, standard_title)\n",
    "        savePCR1figas = f'output/{model}/SinglePCR1plot_{regvar}_{timeframe}_{model}_{variant}_{season}{meantext}{extr_text}.pdf'\n",
    "        PCR1fig.savefig(savePCR1figas)\n",
    "        \n",
    "        \n",
    "        # plot difference plots:\n",
    "        # ---------------------------------------------------\n",
    "        \n",
    "        \n",
    "        # CALCULATE DIFFERENCE:\n",
    "        diff_mean = model_regdata_mean - obs_regdata_mean \n",
    "        try:\n",
    "            len(diff_mean.flat)\n",
    "        except TypeError:\n",
    "            len(diff_mean.data.flat)\n",
    "            diff_mean = diff_mean.data\n",
    "            \n",
    "        # spatial mean of differences:\n",
    "        diff_mean_mean = np.average(diff_mean, weights=area_weights)\n",
    "        mean_diff_arr[0,modeli] = diff_mean_mean\n",
    "        \n",
    "        #print(f'Mean difference = {diff_mean_mean:.2f}{regdatatypes_units[regdata_type]}')\n",
    "        #print(f'Highest difference = {np.max(diff_mean):.2f}{regdatatypes_units[regdata_type]}')\n",
    "        #print(f'Lowest difference = {np.min(diff_mean):.2f}{regdatatypes_units[regdata_type]}')\n",
    "        \n",
    "        # calculate & plot p-value of means comparison:\n",
    "        diff_mean_p = z_test_two_means(model_reg_data,obs_reg_data)\n",
    "        diff_title= f'Prob (p-value) of similarity to ERA5 mean {regdata_type} field'\n",
    "        diff_text = f'Mean difference: {diff_mean_mean:.2f} {regdatatypes_units[regdata_type]}'\n",
    "        diff_plot = plot_diff_p_map(diff_mean_p, lons, lats, regdata_type, fixed_bounds, standard_title, diff_title, diff_text)\n",
    "        savediffmeanas = f'output/{model}/meandifftoERA5_probabilityp_{regvar}_{timeframe}_{model}_{variant}_{season}{meantext}{extr_text}.pdf'\n",
    "        diff_plot.savefig(savediffmeanas)\n",
    "        \n",
    "        # significant difference:\n",
    "        diff_mean_masked = np.ma.masked_where(diff_mean_p > 0.05, diff_mean)\n",
    "        diff_mean_masked_mean = np.average(diff_mean_masked, weights=area_weights)\n",
    "        mean_diff_arr[1,modeli] = diff_mean_masked_mean\n",
    "        print('Significant differences (p<0.05): ')\n",
    "        #try:\n",
    "        print(f'{diff_mean_masked.count()} / {len(diff_mean.flat)} = {(diff_mean_masked.count() / len(diff_mean.flat))*100:.2f} %' )\n",
    "        #except AttributeError:\n",
    "            #print(f'{diff_mean_masked.count()} / {len(diff_mean.data.flat)} = {(diff_mean_masked.count() / len(diff_mean.data.flat))*100:.2f} %' )\n",
    "        \n",
    "        print(f'Mean difference = {diff_mean_masked_mean:.2f}{regdatatypes_units[regdata_type]}')\n",
    "        frac_diff = diff_mean_masked.count() / len(diff_mean.flat)\n",
    "        print(f'Mean diff * frac diff = {diff_mean_masked_mean} * {frac_diff} = {diff_mean_masked_mean * frac_diff}')\n",
    "        #print(f'Highest difference = {np.max(diff_mean_masked):.2f}{regdatatypes_units[regdata_type]}')\n",
    "        #print(f'Lowest difference = {np.min(diff_mean_masked):.2f}{regdatatypes_units[regdata_type]}')\n",
    "        \n",
    "        plotting_modes=['mean+diff','mean+era','diff+era']\n",
    "        plotting_mode = plotting_modes[2]\n",
    "        diff_text= f'Mean difference: {diff_mean_mean:.2f} {regdatatypes_units[regdata_type]}'\n",
    "        mean_diff_plot = plot_mean_plus_diff(model_regdata_mean,diff_mean,obs_regdata_mean,lons,lats,plotting_mode,regdata_type,standard_title,diff_text)\n",
    "        savediffmeanas = f'output/{model}/meanpattern_{plotting_mode}_{regvar}_{timeframe}_{model}_{variant}_{season}{meantext}{extr_text}.pdf'\n",
    "        mean_diff_plot.savefig(savediffmeanas)\n",
    "        \n",
    "        diff_text= f'Mean difference: {diff_mean_masked_mean:.2f} {regdatatypes_units[regdata_type]}'\n",
    "        mean_diff_plot = plot_mean_plus_diff(model_regdata_mean,diff_mean_masked,obs_regdata_mean,lons,lats,plotting_mode,regdata_type,standard_title,diff_text,masked=True)\n",
    "        savediffmeanas = f'output/{model}/meanpattern_{plotting_mode}_masked_{regvar}_{timeframe}_{model}_{variant}_{season}{meantext}{extr_text}.pdf'\n",
    "        mean_diff_plot.savefig(savediffmeanas)\n",
    "        \n",
    "        '''\n",
    "        pcr_diff = obs_coefficients-model_coefficients\n",
    "        diff_title= f'{regdata_type} regression \\n Difference ERA5 - {model} \\n Mean difference: {np.mean(pcr_diff):.2f} {regdatatypes_units[regdata_type]}'\n",
    "        diff_plot = plot_4_diff_map(pcr_diff, lons, lats, model_eofs, regdata_type, fixed_bounds, diff_title, order)\n",
    "        savediffplotas = f'output/{model}/PCR_difftoERA5_{regvar}_{timeframe}_{model}_{variant}_{season}{meantext}{extr_text}.pdf'\n",
    "        diff_plot.savefig(savediffplotas)      \n",
    "        '''\n",
    "\n",
    "        # Calculate comparison metrics:\n",
    "        # ---------------------------------------------------\n",
    "        # mean field gradients:\n",
    "        obs_grads = np.array(calc_gradients(obs_reg_data, lats, lons))\n",
    "        model_grads = np.array(calc_gradients(model_reg_data, lats, lons))\n",
    "        model_rel_grads = (model_grads-obs_grads)/obs_grads\n",
    "        grad_agreement = test_gradient_overlap(obs_grads,model_grads)\n",
    "        NAO_grad[0,modeli] = model_grads[0].nominal_value\n",
    "        NAO_grad[1,modeli] = grad_agreement[0]\n",
    "        #NAO_grad[2,modeli] = model_grads[0].nominal_value-obs_grads[0].nominal_value\n",
    "        print('Z500 gradients, Within 95% CI of ERA5, Difference to ERA5, Rel diff to ERA5 ')\n",
    "        for igrad in range(4):\n",
    "            print(f'{model_grads[igrad]:.2f}, {grad_agreement[igrad]:.2f}, {model_grads[igrad]-obs_grads[igrad]:.2f}, {model_rel_grads[igrad]:.2f}')\n",
    "        #print(f'Z500 gradients: {model_grads}')\n",
    "        #print(f'Within 95% CI of ERA5: {grad_agreement}')\n",
    "        #print(f'Difference to ERA5: {model_grads-obs_grads}')\n",
    "        #print(f'Relative difference to ERA5: {model_rel_grads}')\n",
    "        #print(f'Z500 gradients: {calc_gradients(model_zg_mean, lats, lons)}')\n",
    "        \n",
    "        \n",
    "        ccoef, sdev, mse, rmse = taylor_metrics(ccoef,sdev,mse,rmse,obs_regdata_mean,model_regdata_mean,\n",
    "                                                obs_eofs,model_eofs,obs_coefficients,model_coefficients,\n",
    "                                                obs_corrcoeffs,model_corrcoeffs,\n",
    "                                                corr_threshold,area_weights,modeli,loaddata,models)\n",
    "        \n",
    "        \n",
    "        if Greenland_analysis:\n",
    "        # Greenland focus:\n",
    "        #Greenland: 63-13°W / 59-84°N \n",
    "            model_high_corr_reg_coefficients = np.where(np.logical_or(model_corrcoeffs > corr_threshold, model_corrcoeffs<-corr_threshold), model_coefficients, np.nan)\n",
    "            obs_high_corr_reg_coefficients = np.where(np.logical_or(obs_corrcoeffs > corr_threshold, obs_corrcoeffs<-corr_threshold), obs_coefficients, np.nan)\n",
    "\n",
    "\n",
    "            GL_lat1, GL_lat2 = np.absolute(lats-59).argmin(), np.absolute(lats-84).argmin()\n",
    "            GL_lon1, GL_lon2 = np.absolute(lons-(-63)).argmin(), np.absolute(lons-(-13)).argmin()\n",
    "            GL_model_coefficients = model_coefficients[:,GL_lat1:GL_lat2,GL_lon1:GL_lon2]\n",
    "            GL_obs_coefficients = obs_coefficients[:,GL_lat1:GL_lat2,GL_lon1:GL_lon2]\n",
    "            GL_lons=lons[GL_lon1:GL_lon2]\n",
    "            GL_lats=lats[GL_lat1:GL_lat2]\n",
    "            GL_model_high_corr_reg_coefficients=model_high_corr_reg_coefficients[:,GL_lat1:GL_lat2,GL_lon1:GL_lon2]\n",
    "            GL_obs_high_corr_reg_coefficients=obs_high_corr_reg_coefficients[:,GL_lat1:GL_lat2,GL_lon1:GL_lon2]\n",
    "            GL_model_eofs=model_eofs[:,GL_lat1:GL_lat2,GL_lon1:GL_lon2]\n",
    "            GL_latweights = np.array(np.cos(np.deg2rad(GL_lats)))  \n",
    "            GL_area_weights = np.tile(GL_latweights, (len(GL_lons), 1)).T\n",
    "            if mask_low_corr:\n",
    "                GL_savePCregas=f'output/{model}/PC_{regdatatypes_short[regdata_type]}_{reg_type}_GL_masked_{timeframe}_{model}_{variant}_{season}{meantext}{extr_text}{regridded_text}.pdf'\n",
    "            else:\n",
    "                GL_savePCregas=f'output/{model}/PC_{regdatatypes_short[regdata_type]}_{reg_type}_GL_full_{timeframe}_{model}_{variant}_{season}{meantext}{extr_text}{regridded_text}.pdf'\n",
    "            plot_PCR(fixed_bounds,regdata_type,regdatatypes_units,reg_type,n_colorlevels,GL_model_coefficients,\n",
    "                     GL_lons,GL_lats,\n",
    "                     add_eof_pattern,mark_high_corr,mask_low_corr,\n",
    "                     GL_model_high_corr_reg_coefficients,GL_model_eofs,\n",
    "                     corr_threshold,model_varfrac,standard_title,GL_savePCregas,savePCreg,order)\n",
    "\n",
    "\n",
    "            ccoef, sdev, mse, rmse= GL_taylor_metrics(ccoef,sdev,mse,rmse,GL_obs_coefficients,GL_model_coefficients,\n",
    "                                                      GL_obs_high_corr_reg_coefficients,GL_model_high_corr_reg_coefficients,\n",
    "                                                      GL_area_weights,modeli,loaddata,models)\n",
    "\n",
    "\n",
    "    compmetrics = np.array([ccoef,sdev,mse,rmse])\n",
    "    \n",
    "    skillscore = plot_taylor_diagrams(compmetrics, regvar, models, regdata_type)\n",
    "                                \n",
    "\n",
    "    weighted_score=weighted_skillscore(skillscore,models,timeframe,variants,season,meantext,regridded_text,\n",
    "                                       regvar,regdata_type,obs_varfrac)   \n",
    "    \n",
    "    plot_mean_diff_ranking(mean_diff_arr, regvar, models, regdata_type, regdatatypes_units)\n",
    "    plot_meandiffs(lons, lats, mean_diff_arr, models, variants, orders, regdata_type, regdatatypes_short, regdatatypes_units)\n",
    "\n",
    "    if (regvar=='zg'):\n",
    "        plot_gradient_ranking(NAO_grad, models)\n",
    "    \n",
    "    if Greenland_analysis:\n",
    "        GL_skillscore = plot_taylor_diagrams(compmetrics, regvar, models, regdata_type, area='Greenland')\n",
    "\n",
    "        GL_weighted_score=weighted_skillscore(GL_skillscore,models,timeframe,variants,season,meantext,regridded_text,\n",
    "                                           regvar,regdata_type,obs_varfrac,area='Greenland')    \n",
    "\n",
    "\n",
    "    \n",
    "    #compmetrics = np.array([ccoef,sdev,mse,rmse,skillscore])\n",
    "    \n",
    "    # save comparison metrics:\n",
    "    if savemetrics:\n",
    "        #compmetrics = np.array([ccoef,sdev,mse,rmse])\n",
    "        np.save(f'data/compmetrics_{regvar}',compmetrics)\n",
    "        np.save(f'data/skillscore_{regvar}',skillscore)\n",
    "        np.save(f'data/weightedskillscore_{regvar}',weighted_score)\n",
    "        np.save(f'data/mean_diff_{regvar}', mean_diff_arr)\n",
    "                                  \n",
    "            \n",
    "            \n",
    "    \n",
    "    # plot PCR and Taylor diagram for each PC seperately:\n",
    "    for PCnum in range(4): # 0 for NAO\n",
    "        plot_PCR1(mask_low_corr, add_eof_pattern, corr_threshold, lons, lats, models, variants, orders, \n",
    "                  regdata_type, regdatatypes_short, regdatatypes_units, reg_type, n_colorlevels, PCnum, \n",
    "                  fixed_bounds=True, savefig=True)\n",
    "\n",
    "        plot_1_taylor_diagram(compmetrics, regvar, models, regdata_type, PCnum, area='')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "plot_eigenvalues(models, variants)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d36db8",
   "metadata": {},
   "source": [
    "## Further analysis and plotting figures (optional)\n",
    "This is just a collection of code to make some further analyses and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce023fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the exact locations of the min and max values of the regression:\n",
    "\n",
    "maxreg = np.argmax(model_coefficients[0,:])\n",
    "model_coefficients[0,:].flat[maxreg]\n",
    "#lats.flat[maxreg]\n",
    "\n",
    "\n",
    "PCnum = 0\n",
    "maxreg = np.argmax(model_coefficients[PCnum,:])\n",
    "ind = np.unravel_index(maxreg, (len(lats),len(lons)))\n",
    "print(f'Max PC {PCnum+1} {regdata_type} regression value: {model_coefficients[PCnum,:].flat[maxreg]} at lat: {lats[ind[0]]} , lon: {lons[ind[1]]} ')\n",
    "\n",
    "minreg = np.argmin(model_coefficients[PCnum,:])\n",
    "ind = np.unravel_index(minreg, (len(lats),len(lons)))\n",
    "print(f'Min PC {PCnum+1} {regdata_type} regression value: {model_coefficients[PCnum,:].flat[minreg]} at lat: {lats[ind[0]]} , lon: {lons[ind[1]]} ')\n",
    "\n",
    "\n",
    "lats, lons, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385cc346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure to illustrate the principle of the PC regression:\n",
    "\n",
    "maxreg = np.argmax(model_coefficients[PCnum,:])\n",
    "ind = np.unravel_index(maxreg, (len(lats),len(lons)))\n",
    "print(f'Max PC {PCnum+1} {regdata_type} regression value: {model_coefficients[PCnum,:].flat[maxreg]} at lat: {lats[ind[0]]} , lon: {lons[ind[1]]} ')\n",
    "\n",
    "#minreg = np.argmin(model_coefficients[PCnum,:])\n",
    "#ind = np.unravel_index(minreg, (len(lats),len(lons)))\n",
    "#print(f'Min PC {PCnum+1} {regdata_type} regression value: {model_coefficients[PCnum,:].flat[minreg]} at lat: {lats[ind[0]]} , lon: {lons[ind[1]]} ')\n",
    "\n",
    "\n",
    "col_mean = np.mean(model_reg_data, axis=0)\n",
    "anoms = model_reg_data - col_mean\n",
    "anomaly_ts = anoms[:,ind[0],ind[1]]\n",
    "\n",
    "#anomaly_ts = model_reg_data[:,ind[0],ind[1]] - np.mean(model_reg_data[:,ind[0],ind[1]], axis=0)\n",
    "pc1 = model_pcs[:,0]\n",
    "\n",
    "\n",
    "\n",
    "plt.style.use('default')\n",
    "fig_PC, axs = plt.subplots(2, 1, figsize=(5,5))#, sharex=True)\n",
    "tickmdist = 10  # one tick mark every 10 years\n",
    "\n",
    "ax = axs[0]\n",
    "clrs = ['red' if (x > 0) else 'blue' for x in pc1 ]\n",
    "myxaxis = np.arange(len(pc1 ))\n",
    "ax.bar(myxaxis, pc1 , color=clrs)\n",
    "myticks = np.arange(0,len(myxaxis),tickmdist);\n",
    "mylabels = np.arange(startyear,endyear+1,tickmdist) \n",
    "\n",
    "ax.set_xticks(ticks=myticks); \n",
    "ax.set_xticklabels(labels=mylabels);\n",
    "ax.set_xlabel('Model Years');\n",
    "\n",
    "ax.margins(x=0.005, y=0)\n",
    "ax.set_title(f'PC1 time series', loc='left', fontsize='xx-large');\n",
    "ax.set_ylabel('Standard deviations')\n",
    "\n",
    "\n",
    "ax = axs[1]\n",
    "clrs = ['red' if (x > 0) else 'blue' for x in anomaly_ts]\n",
    "myxaxis = np.arange(len(anomaly_ts))\n",
    "ax.bar(myxaxis, anomaly_ts, color=clrs)\n",
    "myticks = np.arange(0,len(myxaxis),tickmdist);\n",
    "mylabels = np.arange(startyear,endyear+1,tickmdist) \n",
    "\n",
    "ax.set_xticks(ticks=myticks); \n",
    "ax.set_xticklabels(labels=mylabels);\n",
    "ax.set_xlabel('Model Years');\n",
    "\n",
    "ax.margins(x=0.005, y=0)\n",
    "ax.set_title(f'Temperature anomalies', loc='left', fontsize='xx-large');\n",
    "ax.set_ylabel('Temperature [°C]')\n",
    "#fig_PC.suptitle(standard_title)\n",
    "fig_PC.tight_layout()\n",
    "fig_PC.savefig('output/PCR1.pdf')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "ax.scatter(anomaly_ts,pc1,color='black')\n",
    "ax.set(xlabel='Temperature anomalies',ylabel='EOF1 loading')\n",
    "\n",
    "reg = LinearRegression().fit(pc1.reshape(-1, 1), anomaly_ts.reshape(-1, 1))\n",
    "r = reg.coef_[0,0]\n",
    "R = np.corrcoef(pc1,anomaly_ts)[0,1]\n",
    "print(r,R)\n",
    "\n",
    "ax.text(-4,2,f'R = {R:.2f}',fontsize='large')\n",
    "ax.text(-4,1.5,f'r = {r:.2f}',fontsize='large')\n",
    "fig.tight_layout()\n",
    "fig.savefig('output/PCR2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b2e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradfig = plot_EOF1_plus_gradlocs(model_eofs,n_colorlevels,lons,lats,model_varfrac,standard_title,order);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587de9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = ['NAO', 'AR', 'SB', 'WE']\n",
    "for ieof in range(4):\n",
    "    #ieof = 1\n",
    "    compbase = 'highcorr'  # = +4\n",
    "    ss_zg = np.load('data/skillscore_zg.npy')[ieof+4]\n",
    "    ss_tas = np.load('data/skillscore_tas.npy')[ieof+4]\n",
    "    ss_pr = np.load('data/skillscore_pr.npy')[ieof+4]\n",
    "\n",
    "    ss_o = (ss_zg + ss_tas + ss_pr)/3\n",
    "\n",
    "    cell_text=[]\n",
    "    for i in range(len(models)):\n",
    "        if (i==0):\n",
    "            continue\n",
    "        index = np.argsort(ss_o)[::-1][i];\n",
    "        cell_text.append([models[index], np.round(ss_o[index],3)])\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3,5)) ; #, sharey=True);\n",
    "    fig.patch.set_visible(False)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    ax.table(cellText=cell_text, cellLoc='left', colLabels=['Model','Skill Score'],loc='center',bbox = [0, 0, 1, 1])\n",
    "    #ax.set_title(f'Combined PC {ieof+1} Regression Score', loc='left', fontsize='small')\n",
    "    #fig.suptitle(f'Combined PC {ieof+1} Regression Score', fontsize='small')\n",
    "    fig.suptitle(f'Combined {pattern[ieof]} Score', fontsize='large')\n",
    "    fig.tight_layout();\n",
    "    fig.savefig(f'output/taylordiagrams/taylor_scoretables_PC{ieof+1}_allvars_{compbase}.pdf') # {timeframe}\n",
    "    fig.savefig(f'output/plots/taylor_scoretables_PC{ieof+1}_allvars_{compbase}.pdf') # {timeframe}\n",
    "\n",
    "\n",
    "\n",
    "    ss_o = (ss_tas + ss_pr)/2\n",
    "\n",
    "    cell_text=[]\n",
    "    for i in range(len(models)):\n",
    "        if (i==0):\n",
    "            continue\n",
    "        index = np.argsort(ss_o)[::-1][i];\n",
    "        cell_text.append([models[index], np.round(ss_o[index],3)])\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3,7)) ; #, sharey=True);\n",
    "    fig.patch.set_visible(False)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    ax.table(cellText=cell_text, cellLoc='left', colLabels=['Model','Skill Score'],loc='center',bbox = [0, 0, 1, 1])\n",
    "    #ax.set_title(f'Combined PC {ieof+1} Regression Score', loc='left', fontsize='small')\n",
    "    fig.suptitle(f'Combined PC {ieof+1} Temperature & Precipitation Regression Score', fontsize='xx-small')\n",
    "    fig.tight_layout();\n",
    "    fig.savefig(f'output/taylordiagrams/taylor_scoretables_PC{ieof+1}_tas&pr_{compbase}.pdf') # {timeframe}\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # plot difference plots:\n",
    "        # ---------------------------------------------------\n",
    "        \n",
    "        \n",
    "        # CALCULATE DIFFERENCE:\n",
    "        #obs_regdata_mean = np.mean(obs_reg_data, axis=0)\n",
    "        #model_regdata_mean = np.mean(model_reg_data, axis=0)\n",
    "        diff_mean = obs_regdata_mean - model_regdata_mean\n",
    "        try:\n",
    "            len(diff_mean.flat)\n",
    "        except TypeError:\n",
    "            len(diff_mean.data.flat)\n",
    "            diff_mean = diff_mean.data\n",
    "            \n",
    "        # spatial mean of differences:\n",
    "        diff_mean_mean = np.average(diff_mean, weights=area_weights)\n",
    "        \n",
    "        #print(f'Mean difference = {diff_mean_mean:.2f}{regdatatypes_units[regdata_type]}')\n",
    "        #print(f'Highest difference = {np.max(diff_mean):.2f}{regdatatypes_units[regdata_type]}')\n",
    "        #print(f'Lowest difference = {np.min(diff_mean):.2f}{regdatatypes_units[regdata_type]}')\n",
    "        \n",
    "        # calculate & plot p-value of means comparison:\n",
    "        diff_mean_p = z_test_two_means(obs_reg_data,model_reg_data)\n",
    "        #diff_mean_p = np.ma.masked_where(diff_mean_p < 0.05, diff_mean_p)\n",
    "        diff_title= f'Prob (p-value) of similarity to ERA5 mean {regdata_type} field'\n",
    "        diff_text = f'Mean difference: {diff_mean_mean:.2f} {regdatatypes_units[regdata_type]}'\n",
    "        diff_plot = plot_diff_p_map(diff_mean_p, lons, lats, regdata_type, fixed_bounds, standard_title, diff_title, diff_text)\n",
    "        savediffmeanas = f'output/{model}/meandifftoERA5_probabilityp_{regvar}_{timeframe}_{model}_{variant}_{season}{meantext}{extr_text}.pdf'\n",
    "        diff_plot.savefig(savediffmeanas)\n",
    "        \n",
    "        \n",
    "\n",
    "        #'''\n",
    "\n",
    "        # plot difference:\n",
    "        #diff_title= f'Mean field of geopotential height at 500 hPa \\n Difference ERA5 - {model} \\n Mean difference: {np.mean(diff_mean):.2f} hPa'\n",
    "        #diff_title= f'Mean field of {regdata_type} \\n Difference ERA5 - {model} \\n Mean difference: {np.mean(diff_mean):.2f} {regdatatypes_units[regdata_type]}'\n",
    "        diff_title= f'Difference to ERA5 mean {regdata_type} field'\n",
    "        diff_text = f'Mean difference: {diff_mean_mean:.2f} {regdatatypes_units[regdata_type]}'\n",
    "        #diff_colorlevels=np.linspace(-100,100,11)\n",
    "        diff_plot = plot_diff_map(diff_mean, lons, lats, regdata_type, fixed_bounds, standard_title, diff_title, diff_text)\n",
    "        savediffmeanas = f'output/{model}/meandifftoERA5_{regvar}_{timeframe}_{model}_{variant}_{season}{meantext}{extr_text}.pdf'\n",
    "        diff_plot.savefig(savediffmeanas)\n",
    "\n",
    "        # significant difference:\n",
    "        diff_mean_masked = np.ma.masked_where(diff_mean_p > 0.05, diff_mean)\n",
    "        diff_mean_masked_mean = np.average(diff_mean_masked, weights=area_weights)\n",
    "        print('Singificant differences (<5% probability of similarity):')\n",
    "        #try:\n",
    "        print(f'{diff_mean_masked.count()} / {len(diff_mean.flat)} = {(diff_mean_masked.count() / len(diff_mean.flat))*100:.2f} %' )\n",
    "        #except AttributeError:\n",
    "            #print(f'{diff_mean_masked.count()} / {len(diff_mean.data.flat)} = {(diff_mean_masked.count() / len(diff_mean.data.flat))*100:.2f} %' )\n",
    "        \n",
    "        print(f'Mean difference = {diff_mean_masked_mean:.2f}{regdatatypes_units[regdata_type]}')\n",
    "        print(f'Highest difference = {np.max(diff_mean_masked):.2f}{regdatatypes_units[regdata_type]}')\n",
    "        print(f'Lowest difference = {np.min(diff_mean_masked):.2f}{regdatatypes_units[regdata_type]}')\n",
    "        \n",
    "        plotting_modes=['mean+diff','mean+era','diff+era']\n",
    "        plotting_mode = plotting_modes[2]\n",
    "        diff_text= f'Mean difference: {diff_mean_mean:.2f} {regdatatypes_units[regdata_type]}'\n",
    "        mean_diff_plot = plot_mean_plus_diff(model_regdata_mean,diff_mean,obs_regdata_mean,lons,lats,plotting_mode,regdata_type,standard_title,diff_text)\n",
    "        savediffmeanas = f'output/{model}/meanpattern_{plotting_mode}_{regvar}_{timeframe}_{model}_{variant}_{season}{meantext}{extr_text}.pdf'\n",
    "        mean_diff_plot.savefig(savediffmeanas)\n",
    "        \n",
    "        diff_text= f'Mean difference: {diff_mean_masked_mean:.2f} {regdatatypes_units[regdata_type]}'\n",
    "        mean_diff_plot = plot_mean_plus_diff(model_regdata_mean,diff_mean_masked,obs_regdata_mean,lons,lats,plotting_mode,regdata_type,standard_title,diff_text,masked=True)\n",
    "        savediffmeanas = f'output/{model}/meanpattern_{plotting_mode}_masked_{regvar}_{timeframe}_{model}_{variant}_{season}{meantext}{extr_text}.pdf'\n",
    "        mean_diff_plot.savefig(savediffmeanas)\n",
    "        \n",
    "        '''\n",
    "        pcr_diff = obs_coefficients-model_coefficients\n",
    "        diff_title= f'{regdata_type} regression \\n Difference ERA5 - {model} \\n Mean difference: {np.mean(pcr_diff):.2f} {regdatatypes_units[regdata_type]}'\n",
    "        diff_plot = plot_4_diff_map(pcr_diff, lons, lats, model_eofs, regdata_type, fixed_bounds, diff_title, order)\n",
    "        savediffplotas = f'output/{model}/PCR_difftoERA5_{regvar}_{timeframe}_{model}_{variant}_{season}{meantext}{extr_text}.pdf'\n",
    "        diff_plot.savefig(savediffplotas)      \n",
    "        '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac39ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GL_skillscore = plot_taylor_diagrams(compmetrics, regvar, models, regdata_type, area='Greenland')\n",
    "\n",
    "GL_weighted_score=weighted_skillscore(GL_skillscore,models,timeframe,variants,season,meantext,regridded_text,\n",
    "                                   regvar,regdata_type,obs_varfrac,area='Greenland')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b4402",
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = np.sqrt(np.abs(np.cos(np.radians(lats))))[..., np.newaxis]\n",
    "solver = Eof(model_zg_data, weights = wgts, center=True)\n",
    "\n",
    "n = n_eofs\n",
    "eofs = solver.eofs(neofs = n, eofscaling = 0)   \n",
    "    # 0 : Un-scaled EOFs (default).\n",
    "    # 1 : EOFs are divided by the square-root of their eigenvalues.\n",
    "    # 2 : EOFs are multiplied by the square-root of their eigenvalues.\n",
    "\n",
    "pcs = solver.pcs(pcscaling=1, npcs = n)        \n",
    "    # pcscaling=1 : PCs are scaled to unit variance (divided by the square-root of their eigenvalue).\n",
    "    # same effect as dividing by standard deviation\n",
    "\n",
    "\n",
    "varfrac = solver.varianceFraction(n)\n",
    "eigenvalues = solver.eigenvalues(n)\n",
    "\n",
    "errors = solver.northTest(n)\n",
    "errors_scaled = solver.northTest(n, vfscaled=True)\n",
    "\n",
    "varfrac, eigenvalues, errors, errors_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e299bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues/np.sum(eigenvalues), errors/np.sum(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4565aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_varfrac, obs_varfrac)\n",
    "(obs_varfrac - model_varfrac)/obs_varfrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in range(len(models)):\n",
    "\n",
    "    model = models[im]\n",
    "\n",
    "    variant = variants[im]\n",
    "    model_varfrac = np.load(f'data/{model}/varfrac_4EOFs_{timeframe}_{model}_{variant}_{season}_{meantext}{regridded_text}.npy')\n",
    "\n",
    "    model_varfrac= np.array([model_varfrac[0], model_varfrac[2], model_varfrac[1], model_varfrac[3]])\n",
    "    print(model, ':', np.round((obs_varfrac - model_varfrac)/obs_varfrac,3))\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
